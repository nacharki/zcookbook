{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2843865",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Using ZeroEntropy as a Search Tool for Voice AI Agents\n",
    "\n",
    "This cookbook shows how to build a voice assistant that can search through YC company data using ZeroEntropy's MCP server.\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "A voice assistant that:\n",
    "- üé§ Records your voice using Enter key\n",
    "- üîç Searches YC company database via ZeroEntropy\n",
    "- ü§ñ Responds with relevant information\n",
    "- ‚è∏Ô∏è Can be interrupted during responses\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- ZeroEntropy API key ([Get one here](https://dashboard.zeroentropy.dev))\n",
    "- OpenAI API key\n",
    "- Microphone access\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f463b0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, let's install all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96868e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai zeroentropy requests openai-agents sounddevice numpy python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b8016",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Configuration & Setup\n",
    "\n",
    "Create a `.env` file in this directory with your API keys:\n",
    "```\n",
    "ZEROENTROPY_API_KEY=your_zeroentropy_key_here\n",
    "OPENAI_API_KEY=your_openai_key_here\n",
    "```\n",
    "\n",
    "Now let's load configuration and import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "import io\n",
    "import sys\n",
    "import select\n",
    "\n",
    "import dotenv\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from zeroentropy import ZeroEntropy\n",
    "from agents import Agent\n",
    "from agents.mcp import MCPServerSse\n",
    "from agents.voice import (\n",
    "    AudioInput,\n",
    "    SingleAgentVoiceWorkflow,\n",
    "    VoicePipeline,\n",
    "    VoicePipelineConfig,\n",
    "    TTSModelSettings,\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "ZEROENTROPY_API_KEY = os.getenv(\"ZEROENTROPY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COLLECTION_NAME = \"yc_voice_agent_support\"\n",
    "MCP_URL = \"https://openai-deepresearch.zeroentropy.dev/sse/\"\n",
    "YC_API_URL = \"https://yc-oss.github.io/api/companies/all.json\"\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 24000\n",
    "CHANNELS = 1\n",
    "\n",
    "# AI prompts\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You receive transcribed user speech. \"\n",
    "    \"Rewrite the query into a precise search, always call the search tool via MCP, \"\n",
    "    \"fetch results, and answer in English, succinctly.\"\n",
    ")\n",
    "\n",
    "TTS_PROMPT = (\n",
    "    \"You are a helpful voice assistant who can answer any question about any YC company. \"\n",
    "    \"Personality: Helpful and concise voice assistant. \"\n",
    "    \"Tone: Friendly and clear. \"\n",
    "    \"Pause naturally between points.\"\n",
    ")\n",
    "\n",
    "# Initialize clients\n",
    "ze_client = ZeroEntropy(api_key=ZEROENTROPY_API_KEY)\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac913e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Create Collection & Load YC Data\n",
    "\n",
    "We'll create a ZeroEntropy collection and populate it with Y Combinator company data. This will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e501b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection\n",
    "try:\n",
    "    ze_client.collections.add(collection_name=COLLECTION_NAME)\n",
    "    print(f\"‚úÖ Created collection: {COLLECTION_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Collection already exists: {e}\")\n",
    "\n",
    "# Function to load YC company data\n",
    "def setup_yc_data():\n",
    "    \"\"\"Fetch YC companies and add to ZeroEntropy collection.\"\"\"\n",
    "    print(\"üîÑ Fetching YC company data...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(YC_API_URL, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        companies = response.json()\n",
    "        print(f\"üì• Fetched {len(companies)} companies\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch companies: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Add companies to collection\n",
    "    success_count = 0\n",
    "    for company in companies:\n",
    "        try:\n",
    "            slug = str(company.get('slug', ''))\n",
    "            text = (\n",
    "                f\"{company.get('name', '')} ‚Äî {company.get('one_liner', '')}\\n\\n\"\n",
    "                f\"{company.get('long_description', '')}\\n\\n\"\n",
    "                f\"{company.get('website', '')}\\n\\n\"\n",
    "                f\"{company.get('subindustry', '')}\\n\\n\"\n",
    "                f\"Stage: {company.get('stage', '')}\"\n",
    "            )\n",
    "            metadata = {\n",
    "                \"batch\": company.get(\"batch\", \"\"),\n",
    "                \"list:industries\": company.get(\"industries\", []),\n",
    "                \"stage\": company.get(\"stage\", \"\"),\n",
    "            }\n",
    "            \n",
    "            ze_client.documents.add(\n",
    "                collection_name=COLLECTION_NAME,\n",
    "                path=slug,\n",
    "                content={\"type\": \"text\", \"text\": text},\n",
    "                metadata=metadata\n",
    "            )\n",
    "            success_count += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Added {success_count} companies to collection\")\n",
    "    return success_count > 0\n",
    "\n",
    "# Run the setup\n",
    "if setup_yc_data():\n",
    "    print(\"üéâ YC data setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e7c16",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Audio Functions\n",
    "\n",
    "These functions handle recording your voice and transcribing it to text. We use the Enter key instead of space bar to avoid macOS accessibility permission issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4439a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Audio functions ready\n"
     ]
    }
   ],
   "source": [
    "def record_enter_to_talk():\n",
    "    \"\"\"Record audio until Enter key is pressed.\"\"\"\n",
    "    print(\"Press ENTER to start recording, then press ENTER again to stop...\")\n",
    "    \n",
    "    # Wait for first Enter press to start recording\n",
    "    input(\"Press ENTER to start recording: \")\n",
    "    print(\"üé§ Recording... Press ENTER to stop\")\n",
    "    \n",
    "    audio_data = []\n",
    "    recording = True\n",
    "    \n",
    "    def audio_callback(indata, frames, time, status):\n",
    "        if recording:\n",
    "            audio_data.append(indata.copy())\n",
    "    \n",
    "    # Start audio recording\n",
    "    stream = sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        channels=CHANNELS,\n",
    "        dtype=\"int16\",\n",
    "        callback=audio_callback\n",
    "    )\n",
    "    \n",
    "    with stream:\n",
    "        # Wait for second Enter press to stop recording\n",
    "        input()  # This will block until Enter is pressed\n",
    "        recording = False\n",
    "        print(\"‚èπÔ∏è Recording stopped\")\n",
    "    \n",
    "    if audio_data:\n",
    "        return np.concatenate(audio_data, axis=0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_array):\n",
    "    \"\"\"Transcribe audio to text using OpenAI.\"\"\"\n",
    "    audio_bytes = audio_array.tobytes()\n",
    "    audio_file = io.BytesIO(audio_bytes)\n",
    "    audio_file.name = \"user_input.wav\"\n",
    "    \n",
    "    transcript = openai_client.audio.transcriptions.create(\n",
    "        model=\"gpt-4o-transcribe\",\n",
    "        file=audio_file,\n",
    "        response_format=\"text\"\n",
    "    )\n",
    "    \n",
    "    print(f\"You said: {transcript.text}\")\n",
    "    return transcript.text\n",
    "\n",
    "print(\"‚úÖ Audio functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41829dc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Voice Assistant Function\n",
    "\n",
    "This is the main function that ties everything together - it connects to ZeroEntropy via MCP, sets up the voice pipeline, and handles the conversation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419177f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_voice_assistant():\n",
    "    \"\"\"Main voice assistant loop.\"\"\"\n",
    "    print(\"\\nüéôÔ∏è Voice Assistant\")\n",
    "    print(\"üìù Instructions:\")\n",
    "    print(\"   ‚Ä¢ Press ENTER to start recording\")\n",
    "    print(\"   ‚Ä¢ Press ENTER again to stop recording and send\")\n",
    "    print(\"   ‚Ä¢ Press ENTER during AI response to interrupt\")\n",
    "    print(\"   ‚Ä¢ Press Ctrl+C to exit\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Setup MCP connection\n",
    "    async with MCPServerSse(\n",
    "        name=\"ZeroEntropy\",\n",
    "        params={\n",
    "            \"url\": MCP_URL,\n",
    "            \"headers\": {\n",
    "                \"Authorization\": f\"Bearer {ZEROENTROPY_API_KEY}\",\n",
    "                \"X-Collection-Name\": COLLECTION_NAME,\n",
    "            }\n",
    "        },\n",
    "        client_session_timeout_seconds=10.0,\n",
    "    ) as search_server:\n",
    "        \n",
    "        # Create agent\n",
    "        agent = Agent(\n",
    "            name=\"ZeroEntropyVoiceAgent\",\n",
    "            instructions=SYSTEM_PROMPT,\n",
    "            mcp_servers=[search_server],\n",
    "            model=\"gpt-4.1-mini\",\n",
    "        )\n",
    "        \n",
    "        # Setup voice pipeline\n",
    "        tts_settings = TTSModelSettings(instructions=TTS_PROMPT)\n",
    "        voice_config = VoicePipelineConfig(tts_settings=tts_settings)\n",
    "        workflow = SingleAgentVoiceWorkflow(agent)\n",
    "        pipeline = VoicePipeline(workflow=workflow, config=voice_config)\n",
    "        \n",
    "        # Setup audio output\n",
    "        output_stream = sd.OutputStream(\n",
    "            samplerate=SAMPLE_RATE,\n",
    "            channels=CHANNELS,\n",
    "            dtype=\"int16\"\n",
    "        )\n",
    "        output_stream.start()\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # Record user input\n",
    "                audio_array = record_enter_to_talk()\n",
    "                if audio_array is None:\n",
    "                    continue\n",
    "                \n",
    "                # Process request\n",
    "                user_input = AudioInput(buffer=audio_array)\n",
    "                result = await pipeline.run(user_input)\n",
    "                \n",
    "                # Setup interruption detection\n",
    "                stop_playback = threading.Event()\n",
    "                \n",
    "                def monitor_interrupt():\n",
    "                    \"\"\"Monitor for Enter key press to interrupt response.\"\"\"\n",
    "                    try:\n",
    "                        while not stop_playback.is_set():\n",
    "                            if hasattr(select, 'select'):\n",
    "                                ready, _, _ = select.select([sys.stdin], [], [], 0.1)\n",
    "                                if ready:\n",
    "                                    sys.stdin.readline()\n",
    "                                    stop_playback.set()\n",
    "                                    return\n",
    "                            else:\n",
    "                                time.sleep(0.1)\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Start interrupt monitoring thread\n",
    "                interrupt_thread = threading.Thread(target=monitor_interrupt, daemon=True)\n",
    "                interrupt_thread.start()\n",
    "                \n",
    "                # Stream response\n",
    "                print(\"ü§ñ Assistant: \", end=\"\", flush=True)\n",
    "                try:\n",
    "                    async for event in result.stream():\n",
    "                        if stop_playback.is_set():\n",
    "                            print(\"\\n[Interrupted]\")\n",
    "                            break\n",
    "                        if event.type == \"voice_stream_event_audio\":\n",
    "                            output_stream.write(event.data)\n",
    "                        elif event.type == \"voice_stream_event_transcript\":\n",
    "                            print(event.text, end=\"\", flush=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                \n",
    "                # Signal the interrupt thread to stop\n",
    "                stop_playback.set()\n",
    "                print(\"\\n\" + \"-\" * 30)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Goodbye!\")\n",
    "        finally:\n",
    "            output_stream.stop()\n",
    "            output_stream.close()\n",
    "\n",
    "print(\"‚úÖ Voice assistant function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a7e54",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: Run the Voice Assistant\n",
    "\n",
    "Ready to start! This will check your setup and launch the voice assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45bec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable nested asyncio for Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Check API keys first\n",
    "if not ZEROENTROPY_API_KEY or not OPENAI_API_KEY:\n",
    "    print(\"‚ùå Error: Missing API keys!\")\n",
    "    print(\"Please set ZEROENTROPY_API_KEY and OPENAI_API_KEY in your .env file\")\n",
    "else:\n",
    "    print(\"‚úÖ API keys found\")\n",
    "    print(\"üîß Testing audio device...\")\n",
    "    \n",
    "    try:\n",
    "        # Quick audio test\n",
    "        test_audio = sd.rec(int(0.1 * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype=\"int16\")\n",
    "        sd.wait()\n",
    "        print(\"‚úÖ Audio device working\")\n",
    "        print(\"\\nüöÄ Starting Voice Assistant...\")\n",
    "        print(\"üí° Remember: Use ENTER key to control recording\")\n",
    "        \n",
    "        # Run the assistant\n",
    "        await run_voice_assistant()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Audio setup failed: {e}\")\n",
    "        print(\"Please check your microphone and audio permissions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4332e54c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Usage Notes\n",
    "\n",
    "### How to Use:\n",
    "1. **Start Recording**: Press ENTER\n",
    "2. **Stop Recording**: Press ENTER again\n",
    "3. **Interrupt Assistant**: Press ENTER while AI is speaking\n",
    "4. **Exit**: Press Ctrl+C\n",
    "\n",
    "### Example Questions:\n",
    "- \"Tell me about ZeroEntropy?\"\n",
    "- \"What YC companies work on AI in San Francisco?\"\n",
    "- \"Find me companies in healthcare\"\n",
    "- \"What does Stripe do?\"\n",
    "\n",
    "### Troubleshooting:\n",
    "- **No audio**: Check microphone permissions and connection\n",
    "- **API errors**: Verify your API keys in the `.env` file\n",
    "- **Interruption not working**: Make sure your terminal supports input during execution\n",
    "\n",
    "### Key Features:\n",
    "- ‚úÖ **Interrupt capability** - Stop AI responses anytime\n",
    "- ‚úÖ **Real-time search** - Connects to live YC company database\n",
    "- ‚úÖ **Voice-to-voice** - Full speech input and output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
